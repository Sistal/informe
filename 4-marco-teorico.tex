\chapter{MARCO TEÓRICO}

\section{Sistemas de información y su rol en las organizaciones}

La \textbf{Tecnología de Información (TI)} consiste en todo el \textit{hardware} y \textit{software} que necesita usar una empresa para poder cumplir con sus objetivos de negocios, siendo hardware todo equipo de cómputo físico tangible, como un dispositivo de almacenamiento o dispositivo móvil y software como un sistema operativo Windows o Linux, como los miles de programas o aplicaciones móviles. Mientras que un \textbf{Sistemas de Información (SI)}, puede plantearse como un conjunto de componentes interrelacionados que recolectan (o recuperan), procesan, almacenan y distribuyen información para apoyar los procesos de toma de decisiones y de control en una organización \parencite{Laudons2012}.

De acuerdo a \textcite{Impact1991}, los sistemas de información no solo automatizan tareas operativas, sino que transforman las estructuras y los mecanismos de coordinación dentro y fuera de las empresas. Es decir, dejan de ser simples herramientas de apoyo administrativo para convertirse en factores estratégicos que modifican el funcionamiento organizacional y las dinámicas del mercado. De esta manera, su uso estratégico puede modificar el tamaño, la forma y la distribución del poder dentro de las organizaciones, al mismo tiempo que transforma las relaciones entre las empresas y los mercados, teniendo un gran impacto en las mismas.

Los sistemas de información han transformado de manera profunda la estructura y dinámica de las organizaciones modernas, convirtiéndose en un factor clave tanto en la eficiencia operativa como en la toma de decisiones estratégicas, sin nombrar las grandes inversiones que se realizan para adoptarlas. Su impacto económico se evidencia en la reducción de los costos de transacción (participación en el mercado) y agencia (administración de empleados), lo que permite a las empresas externalizar funciones, optimizar recursos y mantener estructuras más livianas sin disminuir su productividad. Desde una perspectiva organizacional, la tecnología de la información ha favorecido el aplanamiento jerárquico (disminución de gerencia y empleados) y la descentralización de la toma de decisiones, al proporcionar información oportuna y accesible a distintos niveles de la empresa. Esto ha impulsado la creación de organizaciones más flexibles y basadas en el conocimiento, donde el valor se centra en la gestión eficaz de la información. Sin embargo, la adopción de estos sistemas también plantea desafíos relacionados con la resistencia al cambio, la adaptación cultural y la reconfiguración de procesos, factores que deben ser cuidadosamente considerados para garantizar una implementación exitosa y sostenible. \parencite{Laudons2012}

En este contexto, investigaciones más recientes en el campo de los Sistemas de Información amplían la comprensión del impacto organizacional de estas tecnologías, especialmente a partir de la incorporación de capacidades de inteligencia artificial. \textcite{Benbya2021AIOrganizations} sostienen que los sistemas de información basados en IA además de apoyar la toma de decisiones humanas, introducen nuevas formas de automatización, aprendizaje y autonomía que reconfiguran profundamente el trabajo, los mecanismos de control y las estructuras organizacionales. A diferencia de los SI tradicionales, estos sistemas pueden ejecutar acciones, generar recomendaciones complejas y adaptar su comportamiento en función de los datos, desplazando parcialmente la agencia desde los actores humanos hacia componentes algorítmicos. Aunque esto puede parecer un beneficio, los autores recalcan en como este fenómeno genera tensiones organizacionales relevantes, como la automatización frente al aumento de capacidades humanas, la sustitución de tareas frente a la transformación de roles y la redistribución del poder en toma de decisiones dentro de la organización, donde el impacto de los SI deja de ser exclusivamente instrumental y se manifiesta como un fenómeno sociotécnico complejo, en el que factores tecnológicos, organizacionales y humanos interactúan de manera dinámica, planteando nuevos desafíos en términos de gobernanza, responsabilidad y sostenibilidad organizacional.

\section{Ingeniería de Software}

La ingeniería de software es una disciplina de ingeniería que se preocupa de todos los aspectos de la producción de software, desde la concepción inicial hasta la operación y mantenimiento \parencite[21]{Sommerville2016}. 

También, otra forma de definir software son: (1) instrucciones que se ejecutan para lograr funciones deseadas; (2) estructura de datos que permiten a los programas manipular información adecuadamente; y (3) información descriptiva tanto de forma impresa como virtual que describe la operación y uso de los programas \parencite[5]{Pressman2020}. Esto implica que el software no solo son los programas computacionales, un buen software profesional incluye la documentación asociada, librerías, soporte y datos de configuración necesarios para que el programa sea de utilidad \parencite{Sommerville2016}. 

La importancia de esta disciplina radica en la necesidad de desarrollar sistemas confiables, eficientes y seguros que respondan a las demandas de una sociedad cada vez más dependiente de la tecnología. Por un lado, la disciplina de ingeniería se encarga de aplicar métodos, teorías y herramientas de forma controlada y adaptativa, permitiendo obtener productos de alta calidad dentro de los límites de tiempo y presupuesto establecidos. Además, contribuye a reducir los costos a largo plazo asociados con la corrección, validación y mantenimiento de los sistemas, garantizando su capacidad de adaptación ante los constantes cambios tecnológicos y organizacionales. En este sentido, aunque desarrollar software pueda parecer una tarea sencilla, cuando no se aplican adecuadamente los principios, las consecuencias suelen ser significativas. La falta de una metodología estructurada puede derivar en proyectos con sobrecostos, retrasos en los plazos de entrega y productos de baja calidad que no satisfacen las necesidades del usuario \parencite{Sommerville2016}.

\subsection{Metodologías de Desarrollo}

Las metodologías de desarrollo de software surgen como la aplicación práctica de los procesos definidos en la ingeniería de software, estableciendo un marco estructurado que guía las actividades necesarias para crear un producto de calidad. Cada metodología organiza de manera distinta las etapas fundamentales del proceso: comunicación, planificación, modelado, construcción y despliegue, definiendo cómo se relacionan entre sí y cómo fluyen a lo largo del tiempo. Así, dependiendo del enfoque, estas etapas pueden ejecutarse de forma secuencial, iterativa, evolutiva o paralela, adaptándose a las características y necesidades del proyecto. \parencite{Pressman2020}

La metodología en cascada, también conocida como modelo secuencial lineal, representa uno de los enfoques más tradicionales dentro de la ingeniería de software. Se basa en un proceso ordenado y progresivo que avanza de manera lineal desde la comunicación y especificación de requisitos, pasando por la planificación, el modelado y la construcción, hasta llegar a la fase de despliegue y soporte. Este modelo resulta adecuado cuando los requerimientos del sistema están claramente definidos y son estables, como en casos de mejoras o adaptaciones a sistemas existentes. Sin embargo, su rigidez y la falta de retroalimentación temprana suelen dificultar su aplicación en proyectos complejos o cambiantes, donde la aparición tardía de errores o la redefinición de necesidades puede generar retrasos y mayores costos \parencite{Pressman2020}.



Aquí es donde entra la agilidad (también referidas como metodologías ligeras o \textit{lean}). En la ingeniería de software se refiere a la capacidad de los equipos de desarrollo para adaptarse de forma rápida y eficiente a los cambios constantes que surgen durante un proyecto. Más que una simple respuesta al cambio, la agilidad promueve una filosofía de trabajo flexible basada en la colaboración, la comunicación efectiva y la entrega continua de software funcional, poniendo un fuerte énfasis en el modelo incremental. Este enfoque integra al cliente dentro del proceso de desarrollo, fomenta la reducción de tareas innecesarias y favorece la planificación adaptable ante entornos inciertos. \parencite{Pressman2020}.

\textit{Scrum} es una metodología ágil basada en principios del manifiesto ágil y orientada a gestionar proyectos de forma flexible y colaborativa. Su estructura se organiza en ciclos cortos de trabajo llamados \textit{sprints}, de entre dos y cuatro semanas, durante los cuales un equipo multidisciplinario desarrolla incrementos funcionales del producto. El proceso se apoya en artefactos clave como el \textit{product backlog} (lista priorizada de requerimientos), el \textit{sprint backlog} (tareas seleccionadas para cada \textit{sprint}) y los incrementos de código entregables. A lo largo del desarrollo, se realizan reuniones periódicas (como las \textit{daily scrums}, revisiones y retrospectivas) que facilitan la comunicación, la detección temprana de problemas y la mejora continua. Gracias a esta dinámica iterativa e incremental, Scrum permite adaptarse rápidamente a los cambios y mantener un enfoque constante en la entrega de valor al cliente. \parencite{Pressman2020}.

\subsection{DevOps}

DevOps (\textit{Development \& Operations}) es un enfoque que integra el desarrollo (\textit{Development}) y las operaciones (\textit{Operations}) con el objetivo de unificar ambos procesos bajo los principios ágiles y de desarrollo \textit{lean}. Este modelo busca optimizar todo el ciclo de vida del software mediante una colaboración continua entre los equipos técnicos y operativos. Su flujo de trabajo se basa en etapas que se repiten de manera cíclica: desarrollo, prueba, integración, despliegue y monitoreo continuos. A través de la \textbf{automatización y la retroalimentación constante}, DevOps permite detectar errores tempranamente, reducir tiempos de entrega y mejorar la calidad del producto, acelerando la disponibilidad del software en entornos de producción y favoreciendo la innovación, la satisfacción del cliente y la capacidad de las organizaciones para adaptarse rápidamente a las necesidades del mercado \parencite{Pressman2020}.

\section{Reingeniería de Software}

De acuerdo a \textcite{NIST1991}, existen diversas formas de entender el término reingeniería de software. Entre las interpretaciones más citadas se encuentran 

\begin{itemize}
    \item \textit{Forward engineering}, definido como el proceso tradicional de pasar de abstracciones de alto nivel y diseños independientes de la implementación a la construcción física de un sistema.
    \item \textit{Reverse engineering}, que consiste en analizar un sistema existente para identificar sus componentes y relaciones, y generar representaciones del sistema en otro nivel de abstracción, sin modificarlo. Dentro de esta categoría se incluyen subáreas como redocumentación (creación o revisión de representaciones equivalentes) y recuperación de diseño (identificación de abstracciones de alto nivel mediante información externa y deducción).
    \item \textit{Restructuring}, la transformación de un sistema de una forma de representación a otra al mismo nivel de abstracción, manteniendo su comportamiento externo.
\end{itemize}

Otros autores, como \textcite{RiesgosReengineering2013} definen reingeniería de software, como el examen, reorganización, análisis y modificación de un sistema de software existente. Donde su objetivo principal es mejorar la mantenibilidad del sistema y reconstituirlo en una nueva forma, implementando posteriormente el sistema modificado sin afectar su funcionalidad. Este proceso puede involucrar la reestructuración o recodificación de uno o todos los componentes del sistema legado y combina diversos procesos, tales como ingeniería inversa, redocumentación, traducción y \textit{forward engineering}, aunque \textcite[276]{Sommerville2016} sugiere que idealmente, no deberían hacerse cambios muy grandes a la arquitectura de software con el objetivo de reducir riesgos y costos.

En una revisión más reciente realizada por \textcite{JoivPaper2025}, se amplía esta conceptualización al analizar de manera sistemática los enfoques contemporáneos de reingeniería de software y proponer una visión estructurada del proceso basada en etapas. Según esta revisión, la reingeniería de software suele organizarse en una secuencia de fases interrelacionadas: (1) análisis del sistema legado, orientado a comprender su arquitectura, dependencias y problemas técnicos; (2) ingeniería inversa, cuyo propósito es recuperar conocimiento de alto nivel sobre el diseño y la lógica del sistema; (3) restructuración y rediseño, donde se redefinen componentes, arquitecturas o tecnologías manteniendo el comportamiento funcional; (4) reimplementación o modernización, que implica la adaptación a nuevas plataformas, lenguajes o paradigmas; y finalmente (5) validación e implementación, asegurando que el sistema reingenierizado cumpla con los requisitos funcionales y no funcionales originales.

Esto resulta en un proceso complejo que aborda las complejidades de un sistema existente, imponiendo una severidad de desafíos al equipo, como en el caso de que exista falta de documentación del sistema actual o conocimiento de los procesos intrínsecos. Asimismo, existen posibles riesgos que deben considerarse y evaluarse en el proceso, como costos, tiempos extendidos o problemas de rendimiento al utilizar una aproximación inapropiada \textcite{JoivPaper2025}.

\section{Arquitectura de Software}

En el ámbito de la ingeniería de software, el concepto de arquitectura de software ha sido definido de diversas maneras, siendo comúnmente considerada como el ``plano'' o ``hoja de ruta'' de un sistema. Como señala \textcite{RichardsFordArch2020}, ha sido difícil llegar a una definición sólida, sobre todo considerando el constante cambio que sufre el rol de arquitecto, y la aparición de nuevas metodologías y diseños como lo es DevOps. Sin embargo, la definición entregada por los autores la entiende como la combinación de varios elementos fundamentales que, en conjunto, determinan la estructura y el comportamiento del sistema\footnote{Considerando la fecha del texto publicado por los autores \textcite{RichardsFordArch2020}, posiblemente se han puesto de acuerdo en una nueva definición.}. Estos elementos son:

\begin{itemize}
    \item \textbf{La estructura del sistema}, que representa el estilo o patrón arquitectónico adoptado (como microservicios, arquitectura en capas o microkernel). Esta describe cómo se organizan los componentes y cómo interactúan entre sí.
    
    \item \textbf{Las características arquitectónicas}, también conocidas como los ``\textit{-ilities}'', que definen los criterios de éxito del sistema más allá de su funcionalidad, tales como escalabilidad, rendimiento, o seguridad (\textit{scalability, performance, security}).
    
    \item \textbf{Las decisiones arquitectónicas}, que establecen las reglas y restricciones que guían la construcción del sistema, determinando qué está permitido y qué no dentro del diseño técnico.
    
    \item \textbf{Los principios de diseño}, que funcionan como directrices o recomendaciones que orientan a los equipos de desarrollo sin imponer reglas estrictas, promoviendo buenas prácticas y consistencia en las implementaciones.
\end{itemize}

De acuerdo a \textcite{RichardsFordArch2020}, los estilos de arquitectura pueden ser clasificados en dos tipos principales, monolíticos (\textit{monolithic}, una sola unidad de código desplegable) y distribuidos (\textit{distributed}, múltiples unidades de código conectadas por protocolos de acceso remoto). También se menciona la falta total de una estructura como una ``gran bola de barro (\textit{big ball of mud})'', un antipatrón de arquitectura que se debe evitar a toda costa y que ocurre frecuentemente.

% \subsection{Arquitectura Monolítica}

\subsection{Arquitectura de Microservicios}

La arquitectura de microservicios se basa en el desarrollo de pequeñas unidades de software autónomas, llamadas servicios, que trabajan en conjunto para conformar un sistema más amplio. Cada microservicio está diseñado para cumplir una única función o responsabilidad dentro del dominio del negocio, siguiendo el principio de responsabilidad única. Esta división permite que el código se mantenga más cohesionado, legible y fácil de modificar, evitando los problemas comunes de los sistemas monolíticos donde las dependencias internas dificultan el mantenimiento y la evolución del software. En lugar de un solo bloque de código, los microservicios establecen límites claros entre funcionalidades, haciendo más evidente la relación entre cada módulo y su propósito dentro del sistema. \parencite{Newman2015}

Una de las principales características de los microservicios es su autonomía. Cada servicio puede desarrollarse, desplegarse y mantenerse de manera independiente, comunicándose con los demás a través de interfaces bien definidas (APIs). Esto evita el acoplamiento entre componentes y permite realizar cambios o actualizaciones sin afectar el funcionamiento global del sistema. Esta independencia también ofrece la posibilidad de utilizar diferentes tecnologías o lenguajes en cada servicio, seleccionando las herramientas más adecuadas para cada caso, lo que se conoce como heterogeneidad tecnológica. \parencite{Newman2015}

Entre los beneficios más destacados de esta arquitectura se encuentran la escalabilidad, la resiliencia y la facilidad de despliegue. Los microservicios pueden escalarse individualmente, optimizando el uso de recursos y reduciendo costos operativos. Asimismo, en caso de fallos, estos quedan aislados dentro del servicio afectado, evitando que se propague al resto del sistema. Por último, al permitir despliegues pequeños y frecuentes, se reducen los riesgos asociados a las actualizaciones y se acelera la entrega de nuevas funcionalidades al usuario \parencite{Newman2015}. 

% \section{Computación en la Nube}

\section{Contenedores y Orquestación}

\subsection{Contenedores}

Los contenedores son una tecnología que permite empaquetar y ejecutar aplicaciones de forma aislada, junto con todas las dependencias necesarias para su funcionamiento, como bibliotecas, configuraciones y archivos del sistema. A diferencia de las máquinas virtuales, los contenedores comparten el mismo núcleo del sistema operativo, lo que los hace más ligeros, portátiles y eficientes. Su propósito principal es garantizar que una aplicación se ejecute de la misma manera sin importar el entorno, eliminando los conflictos derivados de las diferencias entre sistemas.
Un contenedor se crea a partir de una imagen de contenedor, la cual es un paquete binario que contiene todo lo necesario para ejecutar un programa dentro de un entorno aislado. Estas imágenes suelen construirse en capas, donde cada una agrega o modifica elementos sobre la anterior, permitiendo un almacenamiento y despliegue más eficiente. Existen dos tipos principales de contenedores: los contenedores de sistema, que imitan el comportamiento de una máquina virtual completa, y los contenedores de aplicación, que ejecutan un solo proceso o servicio, siguiendo la filosofía de modularidad y escalabilidad propia de los entornos modernos basados en microservicios.

En este contexto, Docker se ha consolidado como la plataforma más popular para la creación, distribución y ejecución de contenedores. Introducido como un proyecto de código abierto, Docker simplificó la adopción de esta tecnología mediante el uso de un formato estándar de imagen conocido como el formato de imagen Docker, compuesto por capas del sistema de archivos. Este formato permite construir imágenes reutilizables y distribuirlas a través de registros de contenedores (container registries), facilitando la automatización del despliegue en diferentes entornos. Gracias a Docker, los desarrolladores pueden construir aplicaciones portátiles, reproducibles y fácilmente escalables, convirtiendo esta herramienta en un componente esencial de la ingeniería de software moderna y un pilar para arquitecturas basadas en contenedores y microservicios \parencite{BBHK82019}.

\subsection{Kubernetes}

Kubernetes es una plataforma de código abierto diseñada para la orquestación y gestión automatizada de aplicaciones en contenedores, permitiendo su implementación, escalado y mantenimiento de forma eficiente. Desarrollado inicialmente por Google, este sistema se basa en la experiencia adquirida en la administración de infraestructuras distribuidas a gran escala y se ha consolidado como el estándar para la construcción de aplicaciones cloud-native. Su función principal consiste en coordinar múltiples contenedores que conforman un sistema distribuido, garantizando la disponibilidad, escalabilidad y resiliencia de los servicios, incluso ante fallos en componentes individuales. Gracias a su capacidad para abstraer la infraestructura subyacente, Kubernetes puede ejecutarse en entornos locales, nubes públicas o híbridas, facilitando la portabilidad y la eficiencia en la administración de recursos.

Una de las principales fortalezas de Kubernetes radica en su arquitectura declarativa y su enfoque en la infraestructura inmutable. A través de estos principios, los desarrolladores describen el estado deseado del sistema, y Kubernetes se encarga de mantenerlo automáticamente mediante procesos de auto-recuperación (self-healing). Esto permite desplegar actualizaciones, escalar servicios y restaurar fallos sin intervención manual, lo que incrementa la velocidad de desarrollo (velocity) y reduce los errores operativos. En conjunto, estas características convierten a Kubernetes en una herramienta fundamental para la ingeniería de software moderna, al posibilitar la creación de sistemas distribuidos confiables y adaptables a las demandas cambiantes del entorno digital \parencite{BBHK82019}.

\begin{comment}

    COMENTARIO PROFE 

    4.⁠ ⁠MARCO TEÓRICO
    4.1 Conceptos Fundamentales
    •⁠  ⁠Arquitectura Monolítica vs. Microservicios
    •⁠  ⁠Computación en la Nube (Cloud Computing)
    •⁠  ⁠Contenedorización y Orquestación
    •⁠  ⁠Patrones de Diseño para Microservicios
    •⁠  ⁠API Gateway y Service Mesh
    4.2 Tecnologías Relevantes
    •⁠  ⁠Plataformas cloud (AWS, Azure, GCP)
    •⁠  ⁠Contenedores (Docker, Kubernetes)
    •⁠  ⁠Bases de datos distribuidas
    •⁠  ⁠Sistemas de mensajería (Kafka, RabbitMQ)
    •⁠  ⁠Herramientas de monitoreo y observabilidad

    COMENTARIO PROFE YELKA
    
    En el Marco Teórico, que entiendo sería el Capítulo IV, se espera que expliquen en qué consiste la tecnología con la que trabajarán, por ejemplo Devops, Microservicios y todo lo que quieren utilizar en el proyecto. Además de señalar por qué lo usarán, cuáles son sus ventajas y qué tan nueva es esa tecnología.


    
    3. Arquitectura de Software

        1. Arquitectura Monolítica
        2. Microservicios

    4. Computación en la Nube
        1. modelos ass
    
    5. Contenedores y Orquestración
    6. Metodologías DevOps
        1. DevSecOps?


\end{comment}
